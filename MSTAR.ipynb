{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of SAR2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABwElSRJ32eu"
      },
      "source": [
        "# Mounting google drive\n",
        "Location where you can view your files saved on drive.\n",
        "/content/drive/My Drive\n",
        "\n",
        "PS: to run bash command, ''!\" before the command and run the cell.\n",
        "For eg. \"!ls\" "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFduhKK53Hva"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWb4jJt63LgS"
      },
      "source": [
        "cd /content/drive/'My Drive'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4ct72Tb4qUM"
      },
      "source": [
        "cd /content/drive/My Drive/SarData10Class_Lee"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUq_SKtBbZGX"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJypn6ZebZGf"
      },
      "source": [
        "To support both Python 2 and Python 3:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aVlzQJ2bZGq"
      },
      "source": [
        "from __future__ import division, print_function, unicode_literals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttuaZBTCbZG5"
      },
      "source": [
        "To plot figures:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ah0PbNh7bZHA"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lJMZvosbZHX"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnO39HtTRut6"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior() \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fscr-g5WbZHp"
      },
      "source": [
        "# Reproducibility"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdYDGgWabZHw"
      },
      "source": [
        "Reset the default graph (re-run notebook without restarting the kernel):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wSpa5KMbZH6"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "#tf.compat.v1.get_default_graph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52hRNyEybZIF"
      },
      "source": [
        "Set random seed so notebook always produces the same output:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FhwcGuwbZIJ"
      },
      "source": [
        "np.random.seed(42)\n",
        "tf.set_random_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PMWhWYXbZIc"
      },
      "source": [
        "# Load MSTAR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzzXu-q3bZIp"
      },
      "source": [
        "import numpy as np\n",
        "import _pickle as pickle\n",
        "with open('batches.meta','rb') as f1:\n",
        "    metaData = pickle.load(f1)   \n",
        "with open('data_batch_1','rb') as f2:\n",
        "    trainData = pickle.load(f2)   \n",
        "with open('test_batch','rb') as f3:\n",
        "    testData = pickle.load(f3)   \n",
        "mstar=trainData"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mCR4yYcbZJW"
      },
      "source": [
        "Visualizing SAR images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7VnKeOibZJa"
      },
      "source": [
        "dim_x=128\n",
        "dim_y=128\n",
        "n_samples = 10\n",
        "\n",
        "plt.figure(figsize=(n_samples * 2, 3))\n",
        "for index in range(n_samples):\n",
        "    plt.subplot(1, n_samples, index + 1)\n",
        "    sample_image = mstar['data'][index,:].reshape(dim_x, dim_y)\n",
        "    plt.imshow(sample_image, cmap=\"gray\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyUHlH0kiOxX"
      },
      "source": [
        "Test Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_it3NqepiNi_"
      },
      "source": [
        "n_samples = 10\n",
        "#decoder_output = deconv\n",
        "sample_images = testData['data'][:n_samples].reshape([-1, 128, 128, 1])\n",
        "\n",
        "plt.figure(figsize=(n_samples * 2, 3))\n",
        "for index in range(n_samples):\n",
        "    plt.subplot(1, n_samples, index + 1)\n",
        "    sample_image = testData['data'][index,:].reshape(dim_x, dim_y)\n",
        "    plt.imshow(sample_image, cmap=\"gray\")\n",
        "    plt.axis(\"off\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnOqFYVZbZJu"
      },
      "source": [
        "The corresponding labels:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxT2NL4obZKN"
      },
      "source": [
        "# Input Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbSSnS6CbZKQ"
      },
      "source": [
        "Creating a placeholder for the input images (128Ã—128 pixels, 1 color channel = grayscale)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-9gKw06bZKX"
      },
      "source": [
        "X = tf.placeholder(shape=[None, dim_x, dim_y, 1], dtype=tf.float32, name=\"X\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iT8A888lbZKg"
      },
      "source": [
        "# Primary Capsules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65JWCPb_bZKi"
      },
      "source": [
        "The first layer will be composed of N maps of, where each capsule will output \n",
        "an MD activation vector, here N and M are modified for analyzing time required to train each type of model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8jD2r0GbZKo"
      },
      "source": [
        "caps1_n_maps = 1 # so the number of maps will be only 1 (with 256 dim) \n",
        "caps1_n_dims = 256 # dimensions of capsule vector'''\n",
        "\n",
        "'''caps1_n_maps = 2 \n",
        "caps1_n_dims = 128 # dimensions of capsule vector'''\n",
        "\n",
        "'''caps1_n_maps = 4 \n",
        "caps1_n_dims = 64 # dimensions of capsule vector'''\n",
        "\n",
        "'''caps1_n_maps = 8 \n",
        "caps1_n_dims = 32 # dimensions of capsule vector '''\n",
        "\n",
        "'''caps1_n_maps = 16 \n",
        "caps1_n_dims = 16 # dimensions of capsule vector'''\n",
        "\n",
        "'''caps1_n_maps = 32 \n",
        "caps1_n_dims = 8 # dimensions of capsule vector '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viiD4psDbZLg"
      },
      "source": [
        "To compute their outputs, we first apply two regular convolutional layers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9OEqaDXbZLj"
      },
      "source": [
        "conv1_params = {\n",
        "    \"filters\": 256,\n",
        "    \"kernel_size\": 9,\n",
        "    #\"kernel_size\": 5,\n",
        "    \"strides\": 1,\n",
        "    \"padding\": \"valid\",\n",
        "    \"activation\": tf.nn.relu,\n",
        "}\n",
        "\n",
        "conv2_params = {\n",
        "    \"filters\": caps1_n_maps * caps1_n_dims, # 256 convolutional filters\n",
        "    \"kernel_size\": 9,\n",
        "    #\"kernel_size\": 5,\n",
        "    \"strides\": 2,\n",
        "    \"padding\": \"valid\",\n",
        "    \"activation\": tf.nn.relu\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQWph48EbZLq"
      },
      "source": [
        "conv1 = tf.layers.conv2d(X, name=\"conv1\", **conv1_params)\n",
        "conv2 = tf.layers.conv2d(conv1, name=\"conv2\", **conv2_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2DHkOKOhPu8"
      },
      "source": [
        "shape = conv2.get_shape().as_list()\n",
        "caps1_n_caps = caps1_n_maps * int(shape[1] * shape[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKezvjTmbZL-"
      },
      "source": [
        "caps1_raw = tf.reshape(conv2, [-1, caps1_n_caps, caps1_n_dims],\n",
        "                       name=\"caps1_raw\")\n",
        "caps1_raw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOm3trhDbZMo"
      },
      "source": [
        "Defining the `squash()` function, based on equation (1) from the paper:\n",
        "\n",
        "$\\operatorname{squash}(\\mathbf{s}) = \\dfrac{\\|\\mathbf{s}\\|^2}{1 + \\|\\mathbf{s}\\|^2} \\dfrac{\\mathbf{s}}{\\|\\mathbf{s}\\|}$\n",
        "\n",
        "The `squash()` function will squash all vectors in the given array, along the given axis (by default, the last axis)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "No-eWQ_ZbZMs"
      },
      "source": [
        "def squash(s, axis=-1, epsilon=1e-7, name=None):\n",
        "    with tf.name_scope(name, default_name=\"squash\"):\n",
        "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
        "                                     keep_dims=True)\n",
        "        safe_norm = tf.sqrt(squared_norm + epsilon)\n",
        "        squash_factor = squared_norm / (1. + squared_norm)\n",
        "        unit_vector = s / safe_norm\n",
        "        return squash_factor * unit_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoI5gLa1bZM5"
      },
      "source": [
        "Now let's apply this function to get the output $\\mathbf{u}_i$ of each primary capsules $i$ :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPJY62T_bZM7"
      },
      "source": [
        "caps1_output = squash(caps1_raw, name=\"caps1_output\")\n",
        "caps1_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx67fMmJbZNH"
      },
      "source": [
        "# SAR Capsules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjTy8T6YbZNH"
      },
      "source": [
        "To compute the output of the SAR capsules, we must first compute the predicted output vectors (one for each primary / SAR capsule pair). Then we can run the routing by agreement algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDZzSYGebZNI"
      },
      "source": [
        "## Compute the Predicted Output Vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg-Xz-wsbZNJ"
      },
      "source": [
        "The SAR capsule layer contains 10 capsules (one for each class) of 16 dimensions each:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv3MODPBbZNM"
      },
      "source": [
        "caps2_n_caps = 10\n",
        "caps2_n_dims = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EORpcD28bZNe"
      },
      "source": [
        "init_sigma = 0.1\n",
        "\n",
        "W_init = tf.random_normal(\n",
        "    shape=(1, caps1_n_caps, caps2_n_caps, caps2_n_dims, caps1_n_dims),\n",
        "    stddev=init_sigma, dtype=tf.float32, name=\"W_init\")\n",
        "W = tf.Variable(W_init, name=\"W\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5nH6SGRbZNm"
      },
      "source": [
        "Now we can create the first array by repeating `W` once per instance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GABvD8PxbZNo"
      },
      "source": [
        "batch_size = tf.shape(X)[0]\n",
        "W_tiled = tf.tile(W, [batch_size, 1, 1, 1, 1], name=\"W_tiled\")\n",
        "print(batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yu0b1NVjbZNy"
      },
      "source": [
        "caps1_output_expanded = tf.expand_dims(caps1_output, -1,\n",
        "                                       name=\"caps1_output_expanded\")\n",
        "caps1_output_tile = tf.expand_dims(caps1_output_expanded, 2,\n",
        "                                   name=\"caps1_output_tile\")\n",
        "caps1_output_tiled = tf.tile(caps1_output_tile, [1, 1, caps2_n_caps, 1, 1],\n",
        "                             name=\"caps1_output_tiled\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fNh8laibZOI"
      },
      "source": [
        "caps2_predicted = tf.matmul(W_tiled, caps1_output_tiled,\n",
        "                            name=\"caps2_predicted\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-aPTmnAbZON"
      },
      "source": [
        "caps2_predicted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFvn-fjmbZOW"
      },
      "source": [
        "For each instance in the batch (batch size unknown yet, therefore size is \"?\") and for each pair of first and second layer capsules (1152Ã—10) we have created a 16D predicted output column vector (16Ã—1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vq04_w9jbZOX"
      },
      "source": [
        "## Routing by agreement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWEfpzmjbZOY"
      },
      "source": [
        "Initializing the raw routing weights $b_{i,j}$ to zero:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPAJhlGJbZOZ"
      },
      "source": [
        "raw_weights = tf.zeros([batch_size, caps1_n_caps, caps2_n_caps, 1, 1],\n",
        "                       dtype=np.float32, name=\"raw_weights\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLJPukTWbZOf"
      },
      "source": [
        "### Round 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pgRGUYabZOh"
      },
      "source": [
        "Applying the softmax function to compute the routing weights, $\\mathbf{c}_{i} = \\operatorname{softmax}(\\mathbf{b}_i)$ (equation (3) in the paper):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecUft3BkbZOh"
      },
      "source": [
        "routing_weights = tf.nn.softmax(raw_weights, dim=2, name=\"routing_weights\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRn4XZTTbZOl"
      },
      "source": [
        "Computing the weighted sum of all the predicted output vectors for each second-layer capsule, $\\mathbf{s}_j = \\sum\\limits_{i}{c_{i,j}\\hat{\\mathbf{u}}_{j|i}}$ (equation (2)-left in the paper):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIipU-9CbZOm"
      },
      "source": [
        "weighted_predictions = tf.multiply(routing_weights, caps2_predicted,\n",
        "                                   name=\"weighted_predictions\")\n",
        "weighted_sum = tf.reduce_sum(weighted_predictions, axis=1, keep_dims=True,\n",
        "                             name=\"weighted_sum\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrndiW5CbZOx"
      },
      "source": [
        "Applying the squash function to get the outputs of the second layer capsules at the end of the first iteration of the routing by agreement algorithm, $\\mathbf{v}_j = \\operatorname{squash}(\\mathbf{s}_j)$ :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1km1eE1NbZOz"
      },
      "source": [
        "caps2_output_round_1 = squash(weighted_sum, axis=-2,\n",
        "                              name=\"caps2_output_round_1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRCZ53l8bZO4"
      },
      "source": [
        "caps2_output_round_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dH4o9bAkbZPB"
      },
      "source": [
        "### Round 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG3uggSsbZPF"
      },
      "source": [
        "caps2_predicted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TELjbMCDbZPM"
      },
      "source": [
        "Look at the shape of `caps2_output_round_1`, which holds 10 outputs vectors of 16D each, for each instance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZfatpgwbZPQ"
      },
      "source": [
        "caps2_output_round_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dCj_fgNbZPZ"
      },
      "source": [
        "To match shapes we tile the `caps2_output_round_1` array 1152 times (once per primary capsule) along the second dimension:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpRu8SB6bZPb"
      },
      "source": [
        "caps2_output_round_1_tiled = tf.tile(\n",
        "    caps2_output_round_1, [1, caps1_n_caps, 1, 1, 1],\n",
        "    name=\"caps2_output_round_1_tiled\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24xDVFIxbZPh"
      },
      "source": [
        "agreement = tf.matmul(caps2_predicted, caps2_output_round_1_tiled,\n",
        "                      transpose_a=True, name=\"agreement\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUFCCB5mbZPl"
      },
      "source": [
        "Updating the raw routing weights $b_{i,j}$ by adding the scalar product $\\hat{\\mathbf{u}}_{j|i} \\cdot \\mathbf{v}_j$ we just computed: $b_{i,j} \\gets b_{i,j} + \\hat{\\mathbf{u}}_{j|i} \\cdot \\mathbf{v}_j$ (Procedure 1, step 7, in the paper)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBb1BspMbZPm"
      },
      "source": [
        "raw_weights_round_2 = tf.add(raw_weights, agreement,\n",
        "                             name=\"raw_weights_round_2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gby9FlCPbZPu"
      },
      "source": [
        "routing_weights_round_2 = tf.nn.softmax(raw_weights_round_2,\n",
        "                                        dim=2,\n",
        "                                        name=\"routing_weights_round_2\")\n",
        "weighted_predictions_round_2 = tf.multiply(routing_weights_round_2,\n",
        "                                           caps2_predicted,\n",
        "                                           name=\"weighted_predictions_round_2\")\n",
        "weighted_sum_round_2 = tf.reduce_sum(weighted_predictions_round_2,\n",
        "                                     axis=1, keep_dims=True,\n",
        "                                     name=\"weighted_sum_round_2\")\n",
        "caps2_output_round_2 = squash(weighted_sum_round_2,\n",
        "                              axis=-2,\n",
        "                              name=\"caps2_output_round_2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gh4HIk99bZPy"
      },
      "source": [
        "caps2_output = caps2_output_round_2\n",
        "caps2_output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-15y8OGXbZQZ"
      },
      "source": [
        "# Estimated Class Probabilities (Length)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UnPec1hbZQg"
      },
      "source": [
        "def safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False, name=None):\n",
        "    with tf.name_scope(name, default_name=\"safe_norm\"):\n",
        "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
        "                                     keep_dims=keep_dims)\n",
        "        return tf.sqrt(squared_norm + epsilon)\n",
        "\n",
        "y_proba = safe_norm(caps2_output, axis=-2, name=\"y_proba\")\n",
        "y_proba"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmq_uHa8bZQl"
      },
      "source": [
        "To predict the class of each instance, we select the one with the highest estimated probability."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arFe5yotbZQm"
      },
      "source": [
        "y_proba_argmax = tf.argmax(y_proba, axis=2, name=\"y_proba\")\n",
        "y_proba_argmax\n",
        "y_pred = tf.squeeze(y_proba_argmax, axis=[1,2], name=\"y_pred\")\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6-gx_rJbZRr"
      },
      "source": [
        "# Labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9De9pxObZRv"
      },
      "source": [
        "Placeholder for the labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZWWgGLMbZRw"
      },
      "source": [
        "y = tf.placeholder(shape=[None], dtype=tf.int64, name=\"y\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6OwPFJTbZRz"
      },
      "source": [
        "# Margin loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGxUAqgAbZR5"
      },
      "source": [
        "m_plus = 0.9\n",
        "m_minus = 0.1\n",
        "lambda_ = 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt7zxf_CbZR-"
      },
      "source": [
        "T = tf.one_hot(y, depth=caps2_n_caps, name=\"T\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsD8GLHybZSd"
      },
      "source": [
        "caps2_output_norm = safe_norm(caps2_output, axis=-2, keep_dims=True,\n",
        "                              name=\"caps2_output_norm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgPKwtVfbZSi"
      },
      "source": [
        "present_error_raw = tf.square(tf.maximum(0., m_plus - caps2_output_norm),\n",
        "                              name=\"present_error_raw\")\n",
        "present_error = tf.reshape(present_error_raw, shape=(-1, 10),\n",
        "                           name=\"present_error\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7uep0jUbZSq"
      },
      "source": [
        "absent_error_raw = tf.square(tf.maximum(0., caps2_output_norm - m_minus),\n",
        "                             name=\"absent_error_raw\")\n",
        "absent_error = tf.reshape(absent_error_raw, shape=(-1, 10),\n",
        "                          name=\"absent_error\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6rHIRQCbZSv"
      },
      "source": [
        "L = tf.add(T * present_error, lambda_ * (1.0 - T) * absent_error,\n",
        "           name=\"L\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzhPcfQbbZSz"
      },
      "source": [
        "Summing the SAR losses for each instance ($L_0 + L_1 + \\cdots + L_9$), and computing the mean over all instances. This is the final margin loss:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R7qJ-PhbZS0"
      },
      "source": [
        "margin_loss = tf.reduce_mean(tf.reduce_sum(L, axis=1), name=\"margin_loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKwe_IrubZS2"
      },
      "source": [
        "# Reconstruction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2WwkWgDbZS4"
      },
      "source": [
        "Now let's add a decoder network on top of the capsule network. A typical Capsnet achitecture has a regular 3-layer fully connected neural network which will learn to reconstruct the input images based on the output of the capsule network. This will force the capsule network to preserve all the information required to reconstruct the images, across the whole network. This constraint regularizes the model: it reduces the risk of overfitting the training set, and it helps generalize to new images. We have modified this decoder network and designed a transposed convolution network which is computationally less expensive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI5hMQRxbZS5"
      },
      "source": [
        "## Mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uHDwJJubZS6"
      },
      "source": [
        "The paper mentions that during training, instead of sending all the outputs of the capsule network to the decoder network, we must send only the output vector of the capsule that corresponds to the target class. All the other output vectors must be masked out. At inference time, we must mask all output vectors except for the longest one, i.e., the one that corresponds to the predicted class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CoVbinrbZS9"
      },
      "source": [
        "mask_with_labels = tf.placeholder_with_default(False, shape=(),\n",
        "                                               name=\"mask_with_labels\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ox-3zf_abZTC"
      },
      "source": [
        "reconstruction_targets = tf.cond(mask_with_labels, # condition\n",
        "                                 lambda: y,        # if True\n",
        "                                 lambda: y_pred,   # if False\n",
        "                                 name=\"reconstruction_targets\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Hz4Mjv4bZTJ"
      },
      "source": [
        "We have the reconstruction targets, so we create the reconstruction mask. It should be equal to 1.0 for the target class, and 0.0 for the other classes, for each instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp4YtVwDbZTK"
      },
      "source": [
        "reconstruction_mask = tf.one_hot(reconstruction_targets,\n",
        "                                 depth=caps2_n_caps,\n",
        "                                 name=\"reconstruction_mask\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXypaaLBbZTN"
      },
      "source": [
        "Let's check the shape of `reconstruction_mask`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpaWjNg1bZTO"
      },
      "source": [
        "reconstruction_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWcJSnZ8bZTg"
      },
      "source": [
        "reconstruction_mask_reshaped = tf.reshape(\n",
        "    reconstruction_mask, [-1, 1, caps2_n_caps, 1, 1],\n",
        "    name=\"reconstruction_mask_reshaped\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiVe-6zCbZTj"
      },
      "source": [
        "caps2_output_masked = tf.multiply(\n",
        "    caps2_output, reconstruction_mask_reshaped,\n",
        "    name=\"caps2_output_masked\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mxb2SJ6KbZTs"
      },
      "source": [
        "caps2_output_masked"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClywbTyZbZTz"
      },
      "source": [
        "'''decoder_input = tf.reshape(caps2_output_masked,\n",
        "                           [-1, caps2_n_caps * caps2_n_dims],\n",
        "                           name=\"decoder_input\")'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWo9iesVtdta"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzfvQHGXbZT_"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65N9n1jTbZUA"
      },
      "source": [
        "Now let's build a modified decoder (which is different from fully connected network). It has five layers of transposed convolution (also called deconvolution) which is much less expensive than the vanilla fully connected decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15WL_wFPtgzE"
      },
      "source": [
        "decoder_input = caps2_output_masked\n",
        "decoder_input = tf.reshape(decoder_input, [-1, 1, 1, 160])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csOoJNxmLscc"
      },
      "source": [
        "filters1 = tf.get_variable('w10', [8, 8, 16, 160], initializer=tf.truncated_normal_initializer(stddev=5e-2, dtype=tf.float32), dtype=tf.float32)\n",
        "strides1 = [1, 2, 2, 1]\n",
        "\n",
        "filters2 = tf.get_variable('w11', [3, 3, 32, 16], initializer=tf.truncated_normal_initializer(stddev=5e-2, dtype=tf.float32), dtype=tf.float32)\n",
        "strides2 = [1, 2, 2, 1]\n",
        "\n",
        "filters3 = tf.get_variable('w12', [3, 3, 32, 32], initializer=tf.truncated_normal_initializer(stddev=5e-2, dtype=tf.float32), dtype=tf.float32)\n",
        "strides3 = [1, 2, 2, 1]\n",
        "\n",
        "filters4 = tf.get_variable('w13', [3, 3, 32, 32], initializer=tf.truncated_normal_initializer(stddev=5e-2, dtype=tf.float32), dtype=tf.float32)\n",
        "strides4 = [1, 2, 2, 1]\n",
        "\n",
        "filters5 = tf.get_variable('w14', [3, 3, 1, 32], initializer=tf.truncated_normal_initializer(stddev=5e-2, dtype=tf.float32), dtype=tf.float32)\n",
        "strides5 = [1, 2, 2, 1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BghBj2xZMudJ"
      },
      "source": [
        "output_shape1 = [8, 8, 8, 16]\n",
        "\n",
        "output_shape2 = [8, 16, 16, 32]\n",
        "\n",
        "output_shape3 = [8, 32, 32, 32]\n",
        "\n",
        "output_shape4 = [8, 64, 64, 32]\n",
        "\n",
        "output_shape5 = [8, 128, 128, 1]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bis7IdqjMyzY"
      },
      "source": [
        "deconv1 = tf.nn.conv2d_transpose(decoder_input, filters1, output_shape1, strides1, padding='VALID', data_format='NHWC', dilations=None, name=None)\n",
        "deconv2 = tf.nn.conv2d_transpose(deconv1, filters2, output_shape2, strides2, padding='SAME', data_format='NHWC', dilations=None, name=None)\n",
        "deconv3 = tf.nn.conv2d_transpose(deconv2, filters3, output_shape3, strides3, padding='SAME', data_format='NHWC', dilations=None, name=None)\n",
        "deconv4 = tf.nn.conv2d_transpose(deconv3, filters4, output_shape4, strides4, padding='SAME', data_format='NHWC', dilations=None, name=None)\n",
        "deconv5 = tf.nn.conv2d_transpose(deconv4, filters5, output_shape5, strides5, padding='SAME', data_format='NHWC', dilations=None, name=None)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3P-A1F0zbZUH"
      },
      "source": [
        "## Reconstruction Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaPEOIC9bZUM"
      },
      "source": [
        "Computing the reconstruction loss. It is the squared difference between the input image and the reconstructed image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZeF4au2bZUM"
      },
      "source": [
        "X_flat = X\n",
        "\n",
        "squared_difference = tf.square(deconv5 - X_flat,\n",
        "                               name=\"squared_difference\")\n",
        "reconstruction_loss = tf.reduce_mean(squared_difference,\n",
        "                                    name=\"reconstruction_loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX9FDsBcbZUP"
      },
      "source": [
        "## Final Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63YZifhubZUQ"
      },
      "source": [
        "The final loss is the sum of the margin loss and the reconstruction loss (scaled down by a factor of 0.0005 to ensure the margin loss dominates training):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuYwQYj6bZUQ"
      },
      "source": [
        "alpha = 0.0005\n",
        "\n",
        "loss = tf.add(margin_loss, alpha * reconstruction_loss, name=\"loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDOmfNf3bZUU"
      },
      "source": [
        "## Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHMyMo6XbZUV"
      },
      "source": [
        "To measure our model's accuracy, we need to count the number of instances that are properly classified. For this, we can simply compare `y` and `y_pred`, convert the boolean value to a float32 (0.0 for False, 1.0 for True), and compute the mean over all the instances:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QjSsUuHbZUW"
      },
      "source": [
        "correct = tf.equal(y, y_pred, name=\"correct\")\n",
        "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AN6juq8QbZUY"
      },
      "source": [
        "## Training Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNVETGiebZUZ"
      },
      "source": [
        "The paper mentions that the authors used the Adam optimizer with TensorFlow's default parameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bQTuzE6bZUa"
      },
      "source": [
        "optimizer = tf.train.AdamOptimizer()\n",
        "training_op = optimizer.minimize(loss, name=\"training_op\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwKPqEQMbZUe"
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdS4Q3k8bZUh"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFgM_72dT1Z2"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_validate, y_train, y_validate = train_test_split( trainData['data'], trainData['labels'], test_size=0.20, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfsHHbEdlQ5O"
      },
      "source": [
        "cd /content/drive/'My Drive'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_9tkiCPbZUj"
      },
      "source": [
        "n_epochs = 5\n",
        "batch_size = 8\n",
        "restore_checkpoint = True\n",
        "n_iterations_per_epoch = X_train.shape[0] // batch_size\n",
        "print(X_train.shape[0])\n",
        "print(X_validate.shape[0])\n",
        "n_iterations_validation = X_validate.shape[0] // batch_size\n",
        "best_loss_val = np.infty\n",
        "checkpoint_path = \"./my_capsule_network\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "b4CxIb4TSRwq"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    if restore_checkpoint and tf.train.checkpoint_exists(checkpoint_path):\n",
        "        #saver.restore(sess, checkpoint_path)\n",
        "        print(\"Here 2\")\n",
        "    else:\n",
        "        init.run()\n",
        "        print(\"Here 3\")\n",
        "    \n",
        "    avg_time = 0\n",
        "    for epoch in range(n_epochs):\n",
        "        curr_batch_size1=0;\n",
        "        curr_batch_size2=0;\n",
        "        start_time = time.time()\n",
        "        #print(\"Here 4\")\n",
        "        for iteration in range(1, n_iterations_per_epoch + 1):\n",
        "            #print(\"Here 5\")\n",
        "            X_batch = X_train[batch_size*curr_batch_size1:batch_size*curr_batch_size1 + batch_size] \n",
        "            y_batch = y_train[batch_size*curr_batch_size1:batch_size*curr_batch_size1 + batch_size]\n",
        "\n",
        "            #print(\"Heere 6\")\n",
        "            # Run the training operation and measure the loss:\n",
        "            _, loss_train = sess.run(\n",
        "                    [training_op, loss],\n",
        "                    feed_dict={X: X_batch.reshape([-1, dim_x, dim_y, 1]),\n",
        "                               y: y_batch,\n",
        "                               mask_with_labels: True})\n",
        "            \n",
        "\n",
        "            print(\"\\rIteration: {}/{} ({:.1f}%)  Loss: {:.5f}\".format(\n",
        "            iteration, n_iterations_per_epoch,\n",
        "            iteration * 100 / n_iterations_per_epoch,\n",
        "            loss_train),\n",
        "            end=\"\")\n",
        "            curr_batch_size1 += 1\n",
        "\n",
        "        total_time = time.time() - start_time\n",
        "        print(f'time for epoch {epoch} is {total_time}')\n",
        "        avg_time += total_time\n",
        "        \n",
        "        # At the end of each epoch,\n",
        "        # measure the validation loss and accuracy:\n",
        "        loss_vals = []\n",
        "        acc_vals = []\n",
        "\n",
        "        for iteration in range(1, n_iterations_validation + 1):\n",
        "            X_batch = X_validate[batch_size*curr_batch_size2:batch_size*curr_batch_size2 + batch_size]\n",
        "            y_batch = y_validate[batch_size*curr_batch_size2:batch_size*curr_batch_size2 + batch_size]\n",
        "            loss_val, acc_val = sess.run(\n",
        "                    [loss, accuracy],\n",
        "                    feed_dict={X: X_batch.reshape([-1, dim_x, dim_y, 1]),\n",
        "                               y: y_batch})\n",
        "            \n",
        "            print(type(loss_val))\n",
        "            loss_vals.append(loss_val)\n",
        "            acc_vals.append(acc_val)\n",
        "            print(\"++++++++++ Validation +++++++++++++++++++++++\")\n",
        "            print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
        "                      iteration, n_iterations_validation,\n",
        "                      iteration * 100 / n_iterations_validation),\n",
        "                      end=\" \" * 10)\n",
        "            curr_batch_size2 += 1\n",
        "            \n",
        "        loss_val = np.mean(loss_vals)\n",
        "        acc_val = np.mean(acc_vals)\n",
        "        print(\"\\rEpoch: {}  Val accuracy: {:.4f}%  Loss: {:.6f}{}\".format(\n",
        "            epoch + 1, acc_val * 100, loss_val,\n",
        "            \" (improved)\" if loss_val < best_loss_val else \"\"))\n",
        "\n",
        "        # And save the model if it improved:\n",
        "        if loss_val < best_loss_val:\n",
        "            save_path = saver.save(sess, checkpoint_path)\n",
        "            best_loss_val = loss_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RykO6VghBgGQ"
      },
      "source": [
        "avg_time /= n_epochs\n",
        "print(avg_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBrpJHaPbZUs"
      },
      "source": [
        "batch_size = 8\n",
        "print(testData['data'].shape[0])\n",
        "\n",
        "n_iterations_test = testData['data'].shape[0] // batch_size\n",
        "curr_batch_size2 = 0\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, checkpoint_path)\n",
        "\n",
        "    loss_tests = []\n",
        "    acc_tests = []\n",
        "    start_time = time.time()\n",
        "    for iteration in range(1, n_iterations_test + 1):\n",
        "        \n",
        "        X_batch = testData['data'][batch_size*curr_batch_size2:batch_size*curr_batch_size2 + batch_size]\n",
        "        y_batch = testData['labels'][batch_size*curr_batch_size2:batch_size*curr_batch_size2 + batch_size]\n",
        "        loss_test, acc_test = sess.run(\n",
        "                [loss, accuracy],\n",
        "                feed_dict={X: X_batch.reshape([-1, dim_x, dim_y, 1]),\n",
        "                           y: y_batch})\n",
        "        loss_tests.append(loss_test)\n",
        "        acc_tests.append(acc_test)\n",
        "        print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
        "                  iteration, n_iterations_test,\n",
        "                  iteration * 100 / n_iterations_test),\n",
        "              end=\" \" * 10)\n",
        "        curr_batch_size2 += 1\n",
        "    total_time = time.time() - start_time\n",
        "    loss_test = np.mean(loss_tests)\n",
        "    acc_test = np.mean(acc_tests)\n",
        "    print(\"\\rFinal test accuracy: {:.4f}%  Loss: {:.6f}\".format(\n",
        "        acc_test * 100, loss_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODZgxaj4qIDN"
      },
      "source": [
        "The time taken to train and test the images is recorded and compared for each type of model ensuring that the accuracy is maintained."
      ]
    }
  ]
}